{"id": "27356214-8c05-45ff-bf64-a5fa4fb2f218", "text": "Q: didSelectAnnotationView not called A: <p>My issue was I had a half sheet in front of my map.  It was a small detent so I didn't understand why my clicks were not getting through to the map.  But to get behind this screen (even if it is not dimmed or blurred) you need to add this to the sheet</p>\n<pre><code>//this is what allows you to interact with the map behind the half modal fyi\nsheet.largestUndimmedDetentIdentifier = .medium\n</code></pre>\n", "tags": ["ios", "swift", "mkannotationview"]}
{"id": "46e80368-cb86-4b83-8a1a-739d4ab71502", "text": "Q: How to handle strict FIFO waiters with futex when a waiter crashes? A: <h2>Preliminary</h2>\n<h3>Syscall wrappers</h3>\n<p>As far as I know, Glibc does not provide syscall wrappers for futex operations, so I'm supposing that the <code>futex_wait()</code> and <code>futex_wake()</code> calls in the example code are your own wrappers, maybe something like this:</p>\n<pre><code>inline static long futex_wait(atomic_uint32_t *futex, uint32_t expected) {\n    return syscall(SYS_futex, futex, FUTEX_WAIT | FUTEX_PRIVATE_FLAG, expected, NULL);\n}\n\ninline static long futex_wake(atomic_uint32_t *futex, uint32_t max_waiters) {\n    return syscall(SYS_futex, futex, FUTEX_WAKE | FUTEX_PRIVATE_FLAG, max_waiters);\n}\n</code></pre>\n<p>The rest of this answer is predicated on that assumption.</p>\n<h3>Incorrect code</h3>\n<p>This ...</p>\n<blockquote>\n<pre><code>// wait until it's my turn\nwhile (atomic_load(&amp;now_serving) != my)\n    futex_wait(&amp;now_serving, my);\n</code></pre>\n</blockquote>\n<p>... is a spinlock with deadlock risk, not the futex-assisted mutex it seems intended to be.</p>\n<p>A futex wait operation is an atomic compare &amp; block (analogous to atomic compare &amp; swap).  The caller is is responsible for specifing the value they expect the futex to have <em>now</em> in order to block, but the example code has just tested that the futex's value is different, so it will usually spin without blocking.  That futex wait will block only if the futex value has been updated since the load to indicate that it is now the current thread's turn -- the exact condition in which you want to avoid blocking.</p>\n<p>You want something more like this:</p>\n<pre><code>while (1) {\n    uint32_t serving = atomic_load(&amp;now_serving);\n    if (serving == my) break;\n    futex_wait(&amp;now_seving, serving);\n}\n</code></pre>\n<p>That blocks if the futex value is unchanged since the preceding read (so it's still not the current thread's turn), but if the futex value is different then it cycles without blocking to test the new value.</p>\n<h3>Weak code</h3>\n<p>In the example code, producers release the lock by calling ...</p>\n<blockquote>\n<pre><code>atomic_fetch_add(&amp;now_serving, 1);\n</code></pre>\n</blockquote>\n<p>.  That's not wrong, but it's not as resilient as it could be, either.  You have an opportunity there to detect errors manifesting as the value of <code>now_serving</code> having been modified unexpectedly:</p>\n<pre><code>uint32_t expected = my;\nif (!atomic_compare_exchange_strong(&amp;now_serving, &amp;expected, expected + 1)) {\n    // ... handle error ...\n}\n</code></pre>\n<p>Aside from the error-handling code itself, that's not more complicated or expensive than what you're doing now, and it will likely save you some grief down the road.</p>\n<h3>Possibly incorrect code</h3>\n<p>You indicate that the consumer is responsible for the <code>futex_wait()</code> call to advise the producers waiting on the lock that it is available, but it must never wake the waiters before the current producer updates the futex value, else they may miss the update, resulting in deadlock. The example code provides no reason to believe that the consumer can be relied upon to get the timing of that call right.</p>\n<p>Perhaps there is some other synchronization between producer and consumer that addresses this issue.  Otherwise, I guess you could let the consumer spinlock until it sees the futex value change, or you could let the producer notify the consumer via a semaphore or some similar mechanism. But in a conventional lock, the thread responsible for updating the futex value would also be responsible for waking waiters.</p>\n<h3>Memory ordering</h3>\n<p>The <code>atomic_fetch_add()</code> and <code>atomic_load()</code> functions provide sequential consistency memory ordering -- the strongest defined by C or most hardware.  That can certainly work, but it is stronger ordering than is typical of mutexes.  Usually, locking a mutex provides acquire memory ordering with respect to the mutex, and unlocking it provides release memory ordering.  These weaker semantics may yield better performance (which is the point of using them).</p>\n<h3>Synchronizing consumer with producers</h3>\n<p>Since the consumer does not acquire the lock, it's unclear how any synchronization between consumer and producers is achieved.  You need that for both memory ordering and operation ordering, and the mechanism used for it is a factor in the kind of robustness you're looking for.</p>\n<h2>Main questions</h2>\n<blockquote>\n<p>If a producer crashes or is killed while holding the current ticket (i.e. <code>now_serving == my</code>), the system can block forever, because no one advances <code>now_serving</code>.</p>\n</blockquote>\n<p>Yes.  And at that level of abstraction, the solution is clear: to avoid deadlocking under such circumstances, another thread must detect the situation and take appropriate action.</p>\n<blockquote>\n<p>In this design, is fail-fast (system restart) the only correct option when the ticket holder crashes, or is there any standard Linux/POSIX mechanism to safely recover from this situation without introducing time-based detection?</p>\n</blockquote>\n<p>Before you even get to fail-fast, you have to have a way to do any kind of failure detection and response at all.</p>\n<p>You say that you want to be purely event driven, but that's incompatible with the kind of robustness you're asking about.  If your threads block waiting exclusively for some event to occur, and it never occurs, then those threads will never proceed.  To avoid that, you need either</p>\n<ul>\n<li>one or more threads having among their responsibilities to monitor for such blockage and take corrective action if it is observed (watchdog or heartbeat monitor), OR</li>\n<li>an alternative way for those threads to proceed on their own (with timeout being the only such option provided by typical futex implementations).</li>\n</ul>\n<p>As long as you rule out all of those, you're stuck with a deadlock risk.  That may be acceptable, though, if the risk of individual threads failing without bringing down the whole program is slim.  And you have a lot of influence over that risk through how you implement the threads' (other) behavior.</p>\n<p><strong>If you do detect a dead or deadlocked thread</strong>, then the viable recovery options depend on program requirements and (much) more implementation detail than is appropriate for SO.  You can certainly have another thread increment the futex value and wake waiters (if any).  You can also have such a thread set some kind of indicator for the dead one, in case it's only <em>mostly</em> dead.<sup>*</sup>  Whether you can ensure that the thread's premature termination does not leave the program in an inconsistent state is is a different question, which only you can answer.  The surest way to avoid any (other) unwanted behavior is to terminate the whole program.</p>\n<blockquote>\n<p>Alternatively, is there any Linux/POSIX synchronization primitive that already provides FIFO wait queues and avoids this problem?</p>\n</blockquote>\n<p>I haven't done this myself, but web sources seem to indicate that if</p>\n<ul>\n<li>you are running on a Linux kernel built with realtime support,</li>\n<li>using schedule policy <code>SCHED_FIFO</code>, and</li>\n<li>you use pthreads mutexes configured for priority inheritance,</li>\n</ul>\n<p>then those mutexes will (also) provide FIFO acquisition order among realtime threads of the same priority.  The mutex setup part might look something like this:</p>\n<pre><code>int config_prio_inherit_mutex(pthread_mutex_t *mutex) {\n    pthread_mutexattr attr;\n    int result;\n\n    result = pthread_mutexattr_init(&amp;attr);\n    // handle errors ...\n    result = pthread_mutexattr_setprotocol(&amp;attr, PTHREAD_PRIO_INHERIT);\n    // handle errors ...\n    result = pthread_mutex_init(mutex, &amp;attr);\n    // handle errors ...\n    return 0;\n}\n</code></pre>\n<p>Other than that, I am not aware of any standard FIFO mutex for Linux.  You're by no means the first to ask for one, so you could probably find a pre-built third-party implementation somewhere, but I don't have any to recommend.</p>\n<hr />\n<p><sup>*</sup> &quot;There's a big difference between mostly dead and all dead.&quot; -- Miracle Max</p>\n", "tags": ["c", "synchronization", "mutex", "fifo", "futex"]}
{"id": "03bdf429-2938-4513-b16f-d4bc35daac91", "text": "Q: Cleared or overwritten Java printed lines stopping program A: <p>The key control characters you're looking for are:</p>\n<ul>\n<li><code>\\r</code> - Carriage Return - move the cursor to the start of the line</li>\n<li><code>\\n</code> - New Line - start a new line</li>\n</ul>\n<p>With these we can build a few operations:</p>\n<ul>\n<li>To write out a line of text, just print it out with <code>System.out.print(...)</code> (omitting the <code>\\n</code>).</li>\n<li>To clear the text, write a line of <code> </code>s as long as the previously written line of text.</li>\n<li>To save the last written line of text, write out a <code>\\n</code> (<code>System.out.print(&quot;\\n&quot;)</code> or <code>System.out.println()</code>)</li>\n</ul>\n", "tags": ["java", "text", "ide"]}
{"id": "572d9206-5160-4787-98fc-3e1387bde68d", "text": "Q: Flipping line of 4-Byte pixels horizontally A: <p>No need to go unsafe. This compiles to very efficient code with only one jump, and even vectorizes nicely when instructions are available:</p>\n<pre class=\"lang-rust prettyprint-override\"><code>fn flip_line(line_bytes: &amp;mut [u8]) {\n    let (line_byte, _) = line_bytes.as_chunks_mut::&lt;BYTES_PER_PIXEL&gt;();\n    // This is a common trick to make multiple bound checks into one.\n    let line_byte = &amp;mut line_byte[..PIXELS_PER_SIDE * 2];\n    for i in 0..PIXELS_PER_SIDE {\n        line_byte.swap(i, line_byte.len() - i - 1);\n    }\n}\n</code></pre>\n", "tags": ["rust", "intrinsics"]}
{"id": "c827dbe3-7d1a-4082-9a5c-ba0e6810fb1c", "text": "Q: Type hinting \u2013 Difference between `Closure` and `callable` A: <p>The difference is that a <a href=\"http://php.net/manual/en/class.closure.php\" rel=\"nofollow noreferrer\"><code>Closure</code></a> (introduced in PHP 5.3) must be an anonymous function, but a <a href=\"http://php.net/manual/en/language.types.callable.php\" rel=\"nofollow noreferrer\"><code>callable</code></a> (introduced in PHP 5.4) can also be a string referencing a named function, or an array referencing an object method.</p>\n<p>You can see/test this with the example below and you will see that you will get an error for the first one:</p>\n<pre class=\"lang-php prettyprint-override\"><code>function callFunc1(Closure $closure) {\n    $closure();\n}\n\nfunction callFunc2(callable $callback) {\n    $callback();\n}\n\nfunction xy() {\n    echo 'Hello, World!';\n}\n\ncallFunc1(&quot;xy&quot;); // Uncaught TypeError: callFunc1(): Argument #1 ($closure) must be of type Closure, string given\ncallFunc2(&quot;xy&quot;); // Hello, World!\n\n// also remember that a Closure *is* a callable\n$xy = function() {\n    echo 'Hello, World';\n};\ncallFunc1($xy); // Hello, World!\ncallFunc2($xy); // Hello, World!\n</code></pre>\n<p>So if you only want to accept anonymous functions, use <code>Closure</code> in the signature. If you also want to allow old-style callbacks, use <code>callable</code> instead.</p>\n", "tags": ["php"]}
{"id": "d4949fab-96ed-4d42-822c-b553a822a3a0", "text": "Q: How to handle tasks that depend on the outcome of other tasks A: <p>According to me, a linked list would be the compatible datastructure for this. Please see the comment on how this is implemented.</p>\n", "tags": ["java", "spring", "java.util.concurrent"]}
